{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Andrew_Ng_at_TechCrunch_Disrupt_SF_2017.jpg/440px-Andrew_Ng_at_TechCrunch_Disrupt_SF_2017.jpg\", #Photo of Andrew Ng\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-01.jpg\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-02.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-03.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-04.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-05.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-06.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-07.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-08.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-09.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-10.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-11.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-12.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-13.png\",\n",
    "    \"https://assets.section508.gov/files/images/authoring-alt-text-figure-14.png\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Andrew_Ng_at_TechCrunch_Disrupt_SF_2017.jpg/440px-Andrew_Ng_at_TechCrunch_Disrupt_SF_2017.jpg\n",
      "Photos and Portraits\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-01.jpg\n",
      "Photos and Portraits\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-02.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-03.png\n",
      "Logos\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-04.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-05.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-06.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-07.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-08.png\n",
      "Controls, Form Elements, and Links\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-09.png\n",
      "Charts, Graphs, and Diagrams\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-10.png\n",
      "Charts, Graphs, and Diagrams\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-11.png\n",
      "Charts, Graphs, and Diagrams\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-12.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-13.png\n",
      "Images that Contain Text\n",
      "https://assets.section508.gov/files/images/authoring-alt-text-figure-14.png\n",
      "Signatures\n"
     ]
    }
   ],
   "source": [
    "import aisuite as ai\n",
    "\n",
    "client = ai.Client()\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an AI assistant trained to classify images from a webpage according to a set of predefined categories. When provided with an image accessed via a URL, you will first use your vision capabilities to analyze the image and then categorize it into one of the following categories:\n",
    "\t1.\tPhotos and Portraits: Realistic photographs or portraits of people, animals, objects, or landscapes.\n",
    "\t2.\tImages that Contain Text: Any image primarily featuring written language or text.\n",
    "\t3.\tLogos: Brand logos, trademarks, or recognizable symbolic icons.\n",
    "\t4.\tDecorative Images: Non-photographic images used primarily for decoration or embellishment (e.g., icons, illustrations without textual content).\n",
    "\t5.\tBackground Images: Images used as page backgrounds, often patterns or scenery behind text or other elements.\n",
    "\t6.\tControls, Form Elements, and Links: Images that represent buttons, icons for interactive elements, or graphical elements directly associated with forms or hyperlinks.\n",
    "\t7.\tBullets: Small graphical elements used to list items or points.\n",
    "\t8.\tSpacers and Separators: Images primarily used to create spacing or to separate sections of content.\n",
    "\t9.\tCharts, Graphs, and Diagrams: Visual representations of data or concepts, including charts, graphs, flowcharts, and diagrams.\n",
    "\t10.\tWatermarks: Semi-transparent images used to brand or mark content, often overlayed on photos.\n",
    "\t11.\tSignatures: Handwritten signatures or stylized name representations.\n",
    "\n",
    "When given the image URL by the user, you will fetch and analyze the image content, then respond with the best fitting category from the above list. If the image could fit multiple categories, choose the one that best describes its primary purpose or appearance.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Below is the URL of an image. Please review it, use your vision capabilities to analyze its content, and classify the image into one of the predefined categories. Respond only with the name of the category.\n",
    "\n",
    "INPUT:\n",
    "\t- IMAGE URL\n",
    "OUTPUT:\n",
    "\t- name of the category from the predefined list\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(test_urls)):\n",
    "\tprint(test_urls[i])\n",
    "\tmessages = [\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"system\", \n",
    "\t\t\t\"content\": system_prompt},\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\", \n",
    "\t\t\t\"content\": [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\"text\": user_prompt,\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\t\"image_url\": {\n",
    "\t\t\t\t\t\t\"url\": f\"{test_urls[i]}\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t},\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t]\n",
    "\n",
    "\tresponse = client.chat.completions.create(\n",
    "\t\tmodel=\"openai:gpt-4o\",\n",
    "\t\tmessages=messages,\n",
    "\t\ttemperature=0.0,\n",
    "\t)\n",
    "\n",
    "\tprint(response.choices[0].message.content)\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altauthor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
